{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP15aOpwIlLwAJ/tlW20VRa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndikaPutra509/Prediksi-Saham/blob/PrediksiSaham/Prediksi_Saham_FIX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tXtNC6XUEuCw",
        "outputId": "731fa5c7-a819-43f0-c5d4-746ce9ee8dae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ta\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    f1_score,\n",
        "    balanced_accuracy_score,\n",
        "    accuracy_score,\n",
        ")\n",
        "from sklearn.ensemble import ExtraTreesClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "fjqp8UPuE79g"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pilih mode: \"harian\" (intraday/hourly) atau \"mingguan\" (daily swing)\n",
        "TRADING_MODE = \"harian\""
      ],
      "metadata": {
        "id": "goJVWVfLFQrz"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYMBOL = \"HOPE.JK\"\n",
        "INTERVAL = \"1h\"\n",
        "START = \"2013-01-01\"\n",
        "END = \"2026-02-27\"\n",
        "INTRADAY_PERIOD = \"720d\"\n",
        "INTRADAY_FALLBACK_PERIODS = [\"720d\", \"365d\", \"180d\", \"90d\", \"60d\", \"30d\", \"10d\", \"5d\", \"3d\"]\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.15\n",
        "HOLD_BAND = 0.05\n",
        "MIN_ROWS_AFTER_FEATURES = 40\n",
        "MIN_ROWS_INTRADAY = 18\n",
        "MIN_RAW_ROWS_FOR_FEATURES = 20\n",
        "AS_OF_DATE = \"2026-02-23\"  # contoh: \"2026-02-18\" atau \"2026-02-18 15:00:00\"\n",
        "IHSG_TICKER = \"^JKSE\"\n",
        "INDO_VIX_CANDIDATES = [\"^JKVIX\", \"JKVIX\", \"VIX.JK\", \"^VIX\", \"VIX\"]\n",
        "GLOBAL_INDEX_TICKERS = {\n",
        "    \"SP500\": \"^GSPC\",\n",
        "    \"NASDAQ\": \"^IXIC\",\n",
        "    \"DOWJONES\": \"^DJI\",\n",
        "    \"NIKKEI\": \"^N225\",\n",
        "    \"SHANGHAI\": \"000001.SS\",\n",
        "}\n",
        "COMMODITY_TICKERS = {\n",
        "    \"OIL\": \"CL=F\",\n",
        "    \"GOLD\": \"GC=F\",\n",
        "}\n",
        "VIX_SPIKE_THRESHOLD = 0.04  # lonjakan 1-periode (4%) dianggap fear naik\n",
        "VIX_HIGH_LEVEL = 25.0\n",
        "USDIDR_TICKER = \"IDR=X\"\n",
        "JKT_TZ = \"Asia/Jakarta\"\n",
        "SESSION1_START = \"09:00:00\"\n",
        "SESSION1_END = \"12:00:00\"\n",
        "SESSION2_START = \"13:30:00\"\n",
        "SESSION2_END = \"16:00:00\"\n",
        "SR_LOOKBACK_DAILY = 20\n",
        "SR_LOOKBACK_INTRADAY = 8"
      ],
      "metadata": {
        "id": "XBU6axLME_SX"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resolve_trading_mode(mode: str) -> dict:\n",
        "    normalized = str(mode).strip().lower()\n",
        "    if normalized not in {\"harian\", \"mingguan\"}:\n",
        "        raise ValueError('TRADING_MODE harus \"harian\" atau \"mingguan\".')\n",
        "\n",
        "    if normalized == \"harian\":\n",
        "        return {\n",
        "            \"name\": \"harian\",\n",
        "            \"interval\": \"1h\",\n",
        "            \"forecast_periods\": 24,\n",
        "            \"forecast_label\": \"Prediksi harga 24 jam ke depan (hourly)\",\n",
        "            \"horizon_note\": \"intraday/day-trading\",\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        \"name\": \"mingguan\",\n",
        "        \"interval\": \"1d\",\n",
        "        \"forecast_periods\": 5,\n",
        "        \"forecast_label\": \"Prediksi harga 1 minggu ke depan (5 hari bursa)\",\n",
        "        \"horizon_note\": \"weekly swing-trading\",\n",
        "    }\n",
        "\n",
        "\n",
        "def get_runtime_mode_config() -> dict:\n",
        "    \"\"\"Ambil config mode terbaru setiap eksekusi (aman untuk notebook/interaktif).\"\"\"\n",
        "    return resolve_trading_mode(TRADING_MODE)\n",
        "\n",
        "\n",
        "def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = df.columns.get_level_values(0)\n",
        "    return df\n",
        "\n",
        "\n",
        "def replace_inf_with_nan(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    num_cols = out.select_dtypes(include=[np.number]).columns\n",
        "    out.loc[:, num_cols] = out.loc[:, num_cols].replace([np.inf, -np.inf], np.nan)\n",
        "    return out\n",
        "\n",
        "\n",
        "def download_data(symbol: str, interval: str, start: str, end: str, intraday_period: str) -> pd.DataFrame:\n",
        "    if interval in {\"1h\", \"60m\", \"30m\", \"15m\", \"5m\", \"1m\"}:\n",
        "        raw = yf.download(symbol, period=intraday_period, interval=interval, auto_adjust=True, progress=True)\n",
        "    else:\n",
        "        raw = yf.download(symbol, start=start, end=end, interval=interval, auto_adjust=True, progress=True)\n",
        "    raw = normalize_columns(raw)\n",
        "    raw = filter_jakarta_sessions(raw, interval)\n",
        "    return raw\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def apply_as_of_cutoff(df: pd.DataFrame, as_of_date: str | None) -> pd.DataFrame:\n",
        "    if as_of_date is None:\n",
        "        return df\n",
        "\n",
        "    cutoff = pd.to_datetime(as_of_date)\n",
        "\n",
        "    # Jika user isi tanggal tanpa jam, anggap sampai akhir hari itu\n",
        "    if len(str(as_of_date)) <= 10:\n",
        "        cutoff = cutoff + pd.Timedelta(days=1) - pd.Timedelta(microseconds=1)\n",
        "\n",
        "    idx = df.index\n",
        "    if isinstance(idx, pd.DatetimeIndex) and idx.tz is not None and cutoff.tzinfo is None:\n",
        "        cutoff = cutoff.tz_localize(idx.tz)\n",
        "\n",
        "    return df.loc[df.index <= cutoff].copy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def apply_idx_to_jakarta(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    if not isinstance(out.index, pd.DatetimeIndex):\n",
        "        return out\n",
        "    if out.index.tz is None:\n",
        "        out.index = out.index.tz_localize(JKT_TZ)\n",
        "    else:\n",
        "        out.index = out.index.tz_convert(JKT_TZ)\n",
        "    return out\n",
        "\n",
        "\n",
        "def filter_jakarta_sessions(df: pd.DataFrame, interval: str) -> pd.DataFrame:\n",
        "    \"\"\"Filter data agar hanya jam perdagangan BEI sesi 1 & 2.\"\"\"\n",
        "    if interval not in {\"1h\", \"60m\", \"30m\", \"15m\", \"5m\", \"1m\"}:\n",
        "        return df\n",
        "\n",
        "    out = apply_idx_to_jakarta(df)\n",
        "    sess1 = out.between_time(SESSION1_START, SESSION1_END, inclusive=\"both\")\n",
        "    sess2 = out.between_time(SESSION2_START, SESSION2_END, inclusive=\"both\")\n",
        "    out = pd.concat([sess1, sess2]).sort_index()\n",
        "\n",
        "    # buang akhir pekan bila ada\n",
        "    if isinstance(out.index, pd.DatetimeIndex):\n",
        "        out = out[out.index.dayofweek < 5]\n",
        "    return out\n",
        "\n",
        "\n",
        "def try_download_close_series(symbol: str, interval: str, start: str, end: str, intraday_period: str, as_of_date: str | None) -> pd.Series | None:\n",
        "    try:\n",
        "        raw = download_data(symbol, interval, start, end, intraday_period)\n",
        "        raw = apply_as_of_cutoff(raw, as_of_date)\n",
        "        if raw.empty or \"Close\" not in raw.columns:\n",
        "            return None\n",
        "        ser = raw[\"Close\"].copy()\n",
        "        ser.name = symbol\n",
        "        return ser\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def add_market_context_features(df: pd.DataFrame, interval: str, start: str, end: str, intraday_period: str, as_of_date: str | None):\n",
        "    out = df.copy()\n",
        "    info = {\n",
        "        \"ihsg_used\": False,\n",
        "        \"indovix_symbol\": None,\n",
        "        \"currency_used\": False,\n",
        "        \"global_markets_used\": 0,\n",
        "        \"commodities_used\": 0,\n",
        "        \"timestamps_aligned\": True,\n",
        "    }\n",
        "\n",
        "    is_intraday = interval in {\"1h\", \"60m\", \"30m\", \"15m\", \"5m\", \"1m\"}\n",
        "    ctx_roll = 12 if is_intraday else 20\n",
        "\n",
        "    ihsg_close = try_download_close_series(IHSG_TICKER, interval, start, end, intraday_period, as_of_date)\n",
        "    if ihsg_close is not None:\n",
        "        ihsg_close = ihsg_close.reindex(out.index).ffill().bfill()\n",
        "        ihsg_ret = ihsg_close.pct_change().replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "        ihsg_ma20 = ihsg_close.rolling(ctx_roll).mean().replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "        out[\"IHSG_Return_1\"] = ihsg_ret\n",
        "        out[\"IHSG_Return_5\"] = ihsg_close.pct_change(5).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "        out[\"IHSG_Volatility_10\"] = ihsg_ret.rolling(10).std().fillna(0.0)\n",
        "        out[\"IHSG_MA20\"] = ihsg_ma20.ffill().bfill()\n",
        "        out[\"IHSG_Trend\"] = (ihsg_close / ihsg_ma20).replace([np.inf, -np.inf], np.nan).ffill().bfill()\n",
        "        out[\"Market_Risk_Regime\"] = (out[\"IHSG_Trend\"] >= 1.0).astype(int)\n",
        "        info[\"ihsg_used\"] = True\n",
        "    else:\n",
        "        out[\"IHSG_Return_1\"] = 0.0\n",
        "        out[\"IHSG_Return_5\"] = 0.0\n",
        "        out[\"IHSG_Volatility_10\"] = 0.0\n",
        "        out[\"IHSG_MA20\"] = 0.0\n",
        "        out[\"IHSG_Trend\"] = 1.0\n",
        "        out[\"Market_Risk_Regime\"] = 0\n",
        "\n",
        "    vix_close = None\n",
        "    for ticker in INDO_VIX_CANDIDATES:\n",
        "        candidate = try_download_close_series(ticker, interval, start, end, intraday_period, as_of_date)\n",
        "        if candidate is not None:\n",
        "            vix_close = candidate\n",
        "            info[\"indovix_symbol\"] = ticker\n",
        "            break\n",
        "\n",
        "    if vix_close is not None:\n",
        "        vix_close = vix_close.reindex(out.index).ffill().bfill()\n",
        "        vix_change = vix_close.pct_change().replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "        out[\"INDOVIX_Level\"] = vix_close.ffill().bfill()\n",
        "        out[\"INDOVIX_Change_1\"] = vix_change\n",
        "        out[\"INDOVIX_Change_5\"] = vix_close.pct_change(5).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "        out[\"VIX_Change\"] = out[\"INDOVIX_Change_1\"]\n",
        "        out[\"VIX_Spike\"] = (out[\"VIX_Change\"] > VIX_SPIKE_THRESHOLD).astype(int)\n",
        "        out[\"VIX_Level\"] = out[\"INDOVIX_Level\"]\n",
        "    else:\n",
        "        out[\"INDOVIX_Level\"] = 0.0\n",
        "        out[\"INDOVIX_Change_1\"] = 0.0\n",
        "        out[\"INDOVIX_Change_5\"] = 0.0\n",
        "        out[\"VIX_Change\"] = 0.0\n",
        "        out[\"VIX_Spike\"] = 0\n",
        "        out[\"VIX_Level\"] = 0.0\n",
        "\n",
        "    # Global market + commodity context\n",
        "    market_return_cols = []\n",
        "    for market_name, market_ticker in GLOBAL_INDEX_TICKERS.items():\n",
        "        market_close = try_download_close_series(market_ticker, interval, start, end, intraday_period, as_of_date)\n",
        "        prefix = f\"GM_{market_name}\"\n",
        "        if market_close is not None:\n",
        "            market_close = market_close.reindex(out.index).ffill().bfill()\n",
        "            market_ret_1 = market_close.pct_change().replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "            market_ret_5 = market_close.pct_change(5).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "            market_trend = (market_close / market_close.rolling(ctx_roll).mean()).replace([np.inf, -np.inf], np.nan).ffill().bfill()\n",
        "            out[f\"{prefix}_Return_1\"] = market_ret_1\n",
        "            out[f\"{prefix}_Return_5\"] = market_ret_5\n",
        "            out[f\"{prefix}_Trend\"] = market_trend\n",
        "            market_return_cols.append(f\"{prefix}_Return_1\")\n",
        "            info[\"global_markets_used\"] += 1\n",
        "        else:\n",
        "            out[f\"{prefix}_Return_1\"] = 0.0\n",
        "            out[f\"{prefix}_Return_5\"] = 0.0\n",
        "            out[f\"{prefix}_Trend\"] = 1.0\n",
        "\n",
        "    commodity_return_cols = []\n",
        "    for commodity_name, commodity_ticker in COMMODITY_TICKERS.items():\n",
        "        commodity_close = try_download_close_series(commodity_ticker, interval, start, end, intraday_period, as_of_date)\n",
        "        prefix = f\"CMDTY_{commodity_name}\"\n",
        "        if commodity_close is not None:\n",
        "            commodity_close = commodity_close.reindex(out.index).ffill().bfill()\n",
        "            commodity_ret_1 = commodity_close.pct_change().replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "            commodity_ret_5 = commodity_close.pct_change(5).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "            commodity_trend = (commodity_close / commodity_close.rolling(ctx_roll).mean()).replace([np.inf, -np.inf], np.nan).ffill().bfill()\n",
        "            out[f\"{prefix}_Return_1\"] = commodity_ret_1\n",
        "            out[f\"{prefix}_Return_5\"] = commodity_ret_5\n",
        "            out[f\"{prefix}_Trend\"] = commodity_trend\n",
        "            commodity_return_cols.append(f\"{prefix}_Return_1\")\n",
        "            info[\"commodities_used\"] += 1\n",
        "        else:\n",
        "            out[f\"{prefix}_Return_1\"] = 0.0\n",
        "            out[f\"{prefix}_Return_5\"] = 0.0\n",
        "            out[f\"{prefix}_Trend\"] = 1.0\n",
        "\n",
        "    if market_return_cols:\n",
        "        out[\"Global_Market_Return_Composite\"] = out[market_return_cols].mean(axis=1)\n",
        "        out[\"Global_Market_Stress\"] = out[market_return_cols].std(axis=1).fillna(0.0)\n",
        "    else:\n",
        "        out[\"Global_Market_Return_Composite\"] = 0.0\n",
        "        out[\"Global_Market_Stress\"] = 0.0\n",
        "\n",
        "    if commodity_return_cols:\n",
        "        out[\"Commodity_Return_Composite\"] = out[commodity_return_cols].mean(axis=1)\n",
        "    else:\n",
        "        out[\"Commodity_Return_Composite\"] = 0.0\n",
        "\n",
        "    # Interaction: kombinasikan global risk proxy dengan INDO VIX\n",
        "    vix_proxy = out[\"INDOVIX_Change_1\"].clip(-0.3, 0.3)\n",
        "    out[\"Global_VIX_Interaction\"] = out[\"Global_Market_Return_Composite\"] * vix_proxy\n",
        "    out[\"Commodity_VIX_Interaction\"] = out[\"Commodity_Return_Composite\"] * vix_proxy\n",
        "\n",
        "    # Currency context (USD/IDR)\n",
        "    usdidr_close = try_download_close_series(USDIDR_TICKER, interval, start, end, intraday_period, as_of_date)\n",
        "    if usdidr_close is not None:\n",
        "        usdidr_close = usdidr_close.reindex(out.index).ffill().bfill()\n",
        "        usdidr_ret = usdidr_close.pct_change().replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "        out[\"USDIDR_Level\"] = usdidr_close\n",
        "        out[\"USDIDR_Return_1\"] = usdidr_ret\n",
        "        out[\"USDIDR_Return_5\"] = usdidr_close.pct_change(5).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "        out[\"USDIDR_Trend\"] = (usdidr_close / usdidr_close.rolling(ctx_roll).mean()).replace([np.inf, -np.inf], np.nan).ffill().bfill()\n",
        "        info[\"currency_used\"] = True\n",
        "    else:\n",
        "        out[\"USDIDR_Level\"] = 0.0\n",
        "        out[\"USDIDR_Return_1\"] = 0.0\n",
        "        out[\"USDIDR_Return_5\"] = 0.0\n",
        "        out[\"USDIDR_Trend\"] = 1.0\n",
        "\n",
        "    # Hindari drop semua baris saat beberapa sumber eksternal kosong/tidak sinkron.\n",
        "    out = replace_inf_with_nan(out)\n",
        "    out = out.ffill().bfill()\n",
        "\n",
        "    for col in out.columns:\n",
        "        if out[col].isna().all():\n",
        "            out[col] = 1.0 if (\"Trend\" in col or col.endswith(\"_Level\")) else 0.0\n",
        "\n",
        "    num_cols = out.select_dtypes(include=[np.number]).columns\n",
        "    out.loc[:, num_cols] = out.loc[:, num_cols].fillna(0.0)\n",
        "\n",
        "    # Pastikan target tetap valid; jika NaN lebih baik dibuang spesifik di target saja.\n",
        "    if \"Target\" in out.columns:\n",
        "        out = out[out[\"Target\"].notna()].copy()\n",
        "\n",
        "    return out, info\n",
        "\n",
        "\n",
        "def build_features(df: pd.DataFrame, interval: str = \"1d\") -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    if len(out) < MIN_RAW_ROWS_FOR_FEATURES:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    close = out[\"Close\"]\n",
        "    high = out[\"High\"]\n",
        "    low = out[\"Low\"]\n",
        "    volume = out[\"Volume\"]\n",
        "\n",
        "    if interval in {\"1h\", \"60m\", \"30m\", \"15m\", \"5m\", \"1m\"}:\n",
        "        ma_short, ma_long = 8, 20\n",
        "        ret_w1, ret_w2 = 3, 6\n",
        "        vol_w1, vol_w2 = 6, 12\n",
        "        lag_list = [1, 2, 3, 4, 6]\n",
        "        roll_ctx = 12\n",
        "    else:\n",
        "        ma_short, ma_long = 20, 50\n",
        "        ret_w1, ret_w2 = 5, 10\n",
        "        vol_w1, vol_w2 = 10, 20\n",
        "        lag_list = [1, 2, 3, 5, 10]\n",
        "        roll_ctx = 20\n",
        "\n",
        "    out[\"RSI\"] = ta.momentum.RSIIndicator(close).rsi()\n",
        "    out[\"MA20\"] = close.rolling(ma_short).mean()\n",
        "    out[\"MA50\"] = close.rolling(ma_long).mean()\n",
        "    out[\"MACD\"] = ta.trend.MACD(close).macd()\n",
        "\n",
        "    bb = ta.volatility.BollingerBands(close)\n",
        "    out[\"BB_high\"] = bb.bollinger_hband()\n",
        "    out[\"BB_low\"] = bb.bollinger_lband()\n",
        "    out[\"BB_width\"] = out[\"BB_high\"] - out[\"BB_low\"]\n",
        "\n",
        "    atr_window = max(2, min(14, len(out)))\n",
        "    out[\"ATR\"] = ta.volatility.AverageTrueRange(high, low, close, window=atr_window).average_true_range()\n",
        "    out[\"OBV\"] = ta.volume.OnBalanceVolumeIndicator(close, volume).on_balance_volume()\n",
        "\n",
        "    out[\"Return\"] = close.pct_change()\n",
        "    out[\"Return_5\"] = close.pct_change(ret_w1)\n",
        "    out[\"Return_10\"] = close.pct_change(ret_w2)\n",
        "    out[\"Volatility_10\"] = out[\"Return\"].rolling(vol_w1).std()\n",
        "    out[\"Volatility_20\"] = out[\"Return\"].rolling(vol_w2).std()\n",
        "    out[\"Volume_Change\"] = volume.pct_change()\n",
        "\n",
        "    for lag in lag_list:\n",
        "        out[f\"Lag_Return_{lag}\"] = out[\"Return\"].shift(lag)\n",
        "        out[f\"Lag_RSI_{lag}\"] = out[\"RSI\"].shift(lag)\n",
        "\n",
        "\n",
        "    # Volume anomaly + buyer/seller pressure proxy\n",
        "    out[\"Candle_Direction\"] = np.sign(out[\"Close\"] - out[\"Open\"])\n",
        "    out[\"Buy_Volume_Proxy\"] = np.where(out[\"Candle_Direction\"] > 0, out[\"Volume\"], 0.0)\n",
        "    out[\"Sell_Volume_Proxy\"] = np.where(out[\"Candle_Direction\"] < 0, out[\"Volume\"], 0.0)\n",
        "\n",
        "    vol_mean_20 = out[\"Volume\"].rolling(roll_ctx).mean()\n",
        "    vol_std_20 = out[\"Volume\"].rolling(roll_ctx).std().replace(0, np.nan)\n",
        "    out[\"Volume_ZScore\"] = ((out[\"Volume\"] - vol_mean_20) / vol_std_20).replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    buy_mean_20 = out[\"Buy_Volume_Proxy\"].rolling(roll_ctx).mean()\n",
        "    buy_std_20 = out[\"Buy_Volume_Proxy\"].rolling(roll_ctx).std().replace(0, np.nan)\n",
        "    sell_mean_20 = out[\"Sell_Volume_Proxy\"].rolling(roll_ctx).mean()\n",
        "    sell_std_20 = out[\"Sell_Volume_Proxy\"].rolling(roll_ctx).std().replace(0, np.nan)\n",
        "\n",
        "    out[\"Buy_Volume_Anomaly\"] = ((out[\"Buy_Volume_Proxy\"] - buy_mean_20) / buy_std_20).replace([np.inf, -np.inf], np.nan)\n",
        "    out[\"Sell_Volume_Anomaly\"] = ((out[\"Sell_Volume_Proxy\"] - sell_mean_20) / sell_std_20).replace([np.inf, -np.inf], np.nan)\n",
        "    out[\"Net_Volume_Anomaly\"] = out[\"Buy_Volume_Anomaly\"] - out[\"Sell_Volume_Anomaly\"]\n",
        "    out[\"Volume_Anomaly_Spike\"] = (out[\"Volume_ZScore\"] > 2.0).astype(int)\n",
        "\n",
        "    # Support / Resistance features (lebih realistis untuk intraday/daily)\n",
        "    if interval in {\"1h\", \"60m\", \"30m\", \"15m\", \"5m\", \"1m\"}:\n",
        "        sr_base = SR_LOOKBACK_INTRADAY\n",
        "    else:\n",
        "        sr_base = SR_LOOKBACK_DAILY\n",
        "    sr_lookback = max(5, min(sr_base, max(5, len(out) - 1)))\n",
        "    out[\"Support_Level\"] = out[\"Low\"].rolling(sr_lookback).min()\n",
        "    out[\"Resistance_Level\"] = out[\"High\"].rolling(sr_lookback).max()\n",
        "    out[\"Distance_To_Support\"] = (out[\"Close\"] - out[\"Support_Level\"]) / out[\"Close\"]\n",
        "    out[\"Distance_To_Resistance\"] = (out[\"Resistance_Level\"] - out[\"Close\"]) / out[\"Close\"]\n",
        "    out[\"Support_Break\"] = (out[\"Close\"] < out[\"Support_Level\"] * 0.999).astype(int)\n",
        "    out[\"Resistance_Break\"] = (out[\"Close\"] > out[\"Resistance_Level\"] * 1.001).astype(int)\n",
        "\n",
        "    out[\"Target\"] = (out[\"Return\"].shift(-1) > 0).astype(int)\n",
        "    out = replace_inf_with_nan(out)\n",
        "    return out.dropna().copy()\n",
        "\n",
        "\n",
        "def safe_auc(y_true: np.ndarray, probs: np.ndarray) -> float:\n",
        "    if len(np.unique(y_true)) < 2:\n",
        "        return float(\"nan\")\n",
        "    return roc_auc_score(y_true, probs)\n",
        "\n",
        "\n",
        "def split_time_series(df: pd.DataFrame):\n",
        "    n = len(df)\n",
        "    if n < 12:\n",
        "        raise ValueError(f\"Data terlalu sedikit setelah feature engineering: {n} baris. Coba perbesar rentang START/END, ganti TRADING_MODE, atau gunakan saham dengan histori lebih panjang.\")\n",
        "\n",
        "    train_end = int(n * TRAIN_RATIO)\n",
        "    val_end = int(n * (TRAIN_RATIO + VAL_RATIO))\n",
        "\n",
        "    # pastikan masing-masing split minimal 1\n",
        "    train_end = max(1, min(train_end, n - 2))\n",
        "    val_end = max(train_end + 1, min(val_end, n - 1))\n",
        "\n",
        "    train_df = df.iloc[:train_end]\n",
        "    val_df = df.iloc[train_end:val_end]\n",
        "    test_df = df.iloc[val_end:]\n",
        "\n",
        "    if len(train_df) == 0 or len(val_df) == 0 or len(test_df) == 0:\n",
        "        raise ValueError(\n",
        "            f\"Split menghasilkan data kosong (train={len(train_df)}, val={len(val_df)}, test={len(test_df)}).\"\n",
        "        )\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "\n",
        "def find_best_threshold(y_true: np.ndarray, probs: np.ndarray) -> float:\n",
        "    if len(y_true) == 0 or len(np.unique(y_true)) < 2:\n",
        "        return 0.5\n",
        "\n",
        "    thresholds = np.arange(0.30, 0.71, 0.01)\n",
        "    best_t, best_bacc, best_f1 = 0.5, -1.0, -1.0\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        bacc = balanced_accuracy_score(y_true, preds)\n",
        "        f1 = f1_score(y_true, preds, zero_division=0)\n",
        "        if (bacc > best_bacc) or (np.isclose(bacc, best_bacc) and f1 > best_f1):\n",
        "            best_t, best_bacc, best_f1 = float(t), float(bacc), float(f1)\n",
        "    return best_t\n",
        "\n",
        "\n",
        "def decide_signal(prob_up: float, threshold: float, hold_band: float = HOLD_BAND) -> str:\n",
        "    upper = threshold + hold_band\n",
        "    lower = threshold - hold_band\n",
        "    if prob_up >= upper and prob_up > 0.5:\n",
        "        return \"BELI\"\n",
        "    if prob_up <= lower and prob_up < 0.5:\n",
        "        return \"JUAL\"\n",
        "    return \"TAHAN\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def interpret_volume_flow(net_anomaly: float, buy_anomaly: float, sell_anomaly: float) -> str:\n",
        "    if any(np.isnan(x) for x in [net_anomaly, buy_anomaly, sell_anomaly]):\n",
        "        return \"Volume flow tidak tersedia\"\n",
        "    if net_anomaly >= 1.0 and buy_anomaly > sell_anomaly:\n",
        "        return \"BUY PRESSURE DOMINAN (anomali beli kuat)\"\n",
        "    if net_anomaly <= -1.0 and sell_anomaly > buy_anomaly:\n",
        "        return \"SELL PRESSURE DOMINAN (anomali jual kuat)\"\n",
        "    return \"Volume flow netral/campuran\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def interpret_sr_breakout(close_price: float, support: float, resistance: float, tol: float = 0.001):\n",
        "    if any(np.isnan(x) for x in [close_price, support, resistance]):\n",
        "        return \"SR tidak tersedia\", 0\n",
        "\n",
        "    if close_price < support * (1 - tol):\n",
        "        return \"SUPPORT JEBOL (bearish breakout)\", -1\n",
        "    if close_price > resistance * (1 + tol):\n",
        "        return \"RESISTANCE JEBOL (bullish breakout)\", 1\n",
        "    return \"Masih di dalam range support-resistance\", 0\n",
        "\n",
        "\n",
        "def adjust_signal_with_vix_fear(signal: str, prob_up: float, vix_level: float | None, vix_change_1: float | None):\n",
        "    \"\"\"\n",
        "    Menyesuaikan signal dengan konteks fear dari Indonesia Volatility Index.\n",
        "    - Jika VIX melonjak/tinggi, sinyal BELI dibuat lebih defensif.\n",
        "    \"\"\"\n",
        "    if signal == \"BELI\":\n",
        "        spike = (vix_change_1 is not None) and (not np.isnan(vix_change_1)) and (vix_change_1 >= VIX_SPIKE_THRESHOLD)\n",
        "        high_level = (vix_level is not None) and (not np.isnan(vix_level)) and (vix_level >= VIX_HIGH_LEVEL)\n",
        "\n",
        "        if spike and high_level:\n",
        "            return \"JUAL\", \"Fear tinggi (VIX spike + level tinggi): BELI diturunkan jadi JUAL defensif\"\n",
        "        if spike or high_level:\n",
        "            return \"TAHAN\", \"Fear meningkat dari INDO VIX: BELI diturunkan jadi TAHAN\"\n",
        "\n",
        "    if signal == \"TAHAN\":\n",
        "        low_fear = (vix_level is not None) and (not np.isnan(vix_level)) and (vix_level < (VIX_HIGH_LEVEL * 0.8))\n",
        "        fear_drop = (vix_change_1 is not None) and (not np.isnan(vix_change_1)) and (vix_change_1 <= -0.03)\n",
        "        if low_fear and fear_drop and prob_up >= 0.58:\n",
        "            return \"BELI\", \"Fear menurun signifikan + probabilitas naik kuat: TAHAN dinaikkan jadi BELI\"\n",
        "\n",
        "    return signal, \"Tidak ada penyesuaian signal dari INDO VIX\"\n",
        "\n",
        "\n",
        "def get_model_candidates():\n",
        "    candidates = {\n",
        "        \"HistGradientBoosting\": HistGradientBoostingClassifier(\n",
        "            learning_rate=0.03,\n",
        "            max_depth=4,\n",
        "            max_iter=400,\n",
        "            min_samples_leaf=20,\n",
        "            random_state=SEED,\n",
        "        ),\n",
        "        \"ExtraTrees\": ExtraTreesClassifier(\n",
        "            n_estimators=700,\n",
        "            max_depth=10,\n",
        "            min_samples_leaf=6,\n",
        "            class_weight=\"balanced_subsample\",\n",
        "            random_state=SEED,\n",
        "            n_jobs=-1,\n",
        "        ),\n",
        "        \"LogisticRegression\": Pipeline(\n",
        "            steps=[\n",
        "                (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "                (\"scaler\", StandardScaler()),\n",
        "                (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=SEED)),\n",
        "            ]\n",
        "        ),\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        from xgboost import XGBClassifier\n",
        "\n",
        "        candidates[\"XGBoost\"] = XGBClassifier(\n",
        "            n_estimators=500,\n",
        "            learning_rate=0.03,\n",
        "            max_depth=4,\n",
        "            subsample=0.9,\n",
        "            colsample_bytree=0.9,\n",
        "            reg_lambda=1.0,\n",
        "            objective=\"binary:logistic\",\n",
        "            eval_metric=\"logloss\",\n",
        "            random_state=SEED,\n",
        "            n_jobs=-1,\n",
        "        )\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return candidates\n",
        "\n",
        "\n",
        "def evaluate_model(name, model, X_train, y_train, X_val, y_val):\n",
        "    model.fit(X_train, y_train)\n",
        "    val_probs = np.nan_to_num(model.predict_proba(X_val)[:, 1], nan=0.5, posinf=1.0, neginf=0.0)\n",
        "    threshold = find_best_threshold(y_val, val_probs)\n",
        "    val_preds = (val_probs >= threshold).astype(int)\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"model\": model,\n",
        "        \"threshold\": threshold,\n",
        "        \"val_auc\": safe_auc(y_val, val_probs),\n",
        "        \"val_bacc\": balanced_accuracy_score(y_val, val_preds),\n",
        "        \"val_acc\": accuracy_score(y_val, val_preds),\n",
        "    }\n",
        "\n",
        "\n",
        "def estimate_expected_return(prob_up: float, return_series: pd.Series) -> float:\n",
        "    up_returns = return_series[return_series > 0]\n",
        "    down_returns = return_series[return_series <= 0]\n",
        "    mean_up = float(up_returns.mean()) if len(up_returns) else 0.0\n",
        "    mean_down = float(down_returns.mean()) if len(down_returns) else 0.0\n",
        "    return (prob_up * mean_up) + ((1 - prob_up) * mean_down)\n",
        "\n",
        "\n",
        "def suggest_stoploss(signal: str, last_close: float, atr_value: float, prob_up: float, base_mult: float = 1.5):\n",
        "    if signal == \"TAHAN\":\n",
        "        return None, None, \"Tidak ada stop-loss karena sinyal TAHAN\"\n",
        "\n",
        "    confidence = abs(prob_up - 0.5) * 2\n",
        "    multiplier = base_mult + (0.7 * confidence)\n",
        "\n",
        "    if atr_value is None or np.isnan(atr_value) or atr_value <= 0:\n",
        "        fallback_pct = 0.03\n",
        "        if signal == \"BELI\":\n",
        "            stop = last_close * (1 - fallback_pct)\n",
        "            return stop, fallback_pct * 100, \"Fallback 3% (ATR tidak valid)\"\n",
        "        stop = last_close * (1 + fallback_pct)\n",
        "        return stop, fallback_pct * 100, \"Fallback 3% (ATR tidak valid, skenario short)\"\n",
        "\n",
        "    if signal == \"BELI\":\n",
        "        stop = last_close - (multiplier * atr_value)\n",
        "        stop_pct = ((last_close - stop) / last_close) * 100\n",
        "        return stop, stop_pct, f\"ATR x {multiplier:.2f} di bawah harga masuk\"\n",
        "\n",
        "    stop = last_close + (multiplier * atr_value)\n",
        "    stop_pct = ((stop - last_close) / last_close) * 100\n",
        "    return stop, stop_pct, f\"ATR x {multiplier:.2f} di atas harga referensi\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_next_bej_session_timestamps(start_ts: pd.Timestamp, periods: int) -> pd.DatetimeIndex:\n",
        "    ts = pd.Timestamp(start_ts)\n",
        "    if ts.tzinfo is None:\n",
        "        ts = ts.tz_localize(JKT_TZ)\n",
        "    else:\n",
        "        ts = ts.tz_convert(JKT_TZ)\n",
        "\n",
        "    session_hours = [9, 10, 11, 12, 14, 15, 16]\n",
        "    out = []\n",
        "    cur = ts\n",
        "\n",
        "    while len(out) < periods:\n",
        "        cur = cur + pd.Timedelta(hours=1)\n",
        "\n",
        "        # normalisasi menit/detik ke jam bulat\n",
        "        cur = cur.replace(minute=0, second=0, microsecond=0)\n",
        "\n",
        "        # jika weekend, lompat ke senin jam 09:00\n",
        "        while cur.dayofweek >= 5:\n",
        "            cur = (cur + pd.Timedelta(days=1)).replace(hour=9, minute=0, second=0, microsecond=0)\n",
        "\n",
        "        if cur.hour in session_hours and cur.dayofweek < 5:\n",
        "            out.append(cur)\n",
        "\n",
        "    return pd.DatetimeIndex(out)\n",
        "\n",
        "\n",
        "def estimate_ihsg_influence_on_latest(model, latest_row: pd.DataFrame) -> tuple[float, float]:\n",
        "    \"\"\"Bandingkan probabilitas dengan vs tanpa fitur IHSG pada baris terakhir.\"\"\"\n",
        "    base_prob = float(np.nan_to_num(model.predict_proba(latest_row)[:, 1], nan=0.5, posinf=1.0, neginf=0.0)[0])\n",
        "\n",
        "    no_ihsg = latest_row.copy()\n",
        "    for c in [\"IHSG_Return_1\", \"IHSG_Return_5\", \"IHSG_Volatility_10\"]:\n",
        "        if c in no_ihsg.columns:\n",
        "            no_ihsg[c] = 0.0\n",
        "\n",
        "    no_ihsg_prob = float(np.nan_to_num(model.predict_proba(no_ihsg)[:, 1], nan=0.5, posinf=1.0, neginf=0.0)[0])\n",
        "    return base_prob, (base_prob - no_ihsg_prob)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def suggest_tp_sl_from_sr(signal: str, entry_price: float, support: float, resistance: float, atr_value: float | None, interval: str = \"1d\"):\n",
        "    \"\"\"\n",
        "    Menentukan take-profit dan stop-loss realistis berbasis level support/resistance.\n",
        "    - BELI: SL di bawah support (atau ATR fallback), TP mendekati resistance.\n",
        "    - JUAL: SL di atas resistance, TP mendekati support.\n",
        "    \"\"\"\n",
        "    if signal == \"TAHAN\":\n",
        "        return None, None, \"Tidak ada TP/SL karena sinyal TAHAN\"\n",
        "\n",
        "    atr_buffer = 0.5 * atr_value if atr_value is not None and not np.isnan(atr_value) and atr_value > 0 else entry_price * 0.005\n",
        "    tp_atr_mult = 1.8 if interval in {\"1h\", \"60m\", \"30m\", \"15m\", \"5m\", \"1m\"} else 2.5\n",
        "    sl_atr_mult = 1.2 if interval in {\"1h\", \"60m\", \"30m\", \"15m\", \"5m\", \"1m\"} else 1.8\n",
        "\n",
        "    if signal == \"BELI\":\n",
        "        sl_floor = entry_price - (sl_atr_mult * atr_buffer)\n",
        "        if not np.isnan(support):\n",
        "            sl = max(support - atr_buffer, sl_floor)\n",
        "        else:\n",
        "            sl = sl_floor\n",
        "\n",
        "        tp_cap = entry_price + (tp_atr_mult * atr_buffer)\n",
        "        if not np.isnan(resistance):\n",
        "            tp = min(resistance - (0.2 * atr_buffer), tp_cap)\n",
        "        else:\n",
        "            tp = tp_cap\n",
        "\n",
        "        if tp <= entry_price:\n",
        "            tp = entry_price * 1.005\n",
        "        if sl >= entry_price:\n",
        "            sl = entry_price * 0.995\n",
        "\n",
        "        return tp, sl, \"TP/SL dari resistance-support + buffer ATR (skenario long)\"\n",
        "\n",
        "    # signal == JUAL (short/defensive)\n",
        "    sl_cap = entry_price + (sl_atr_mult * atr_buffer)\n",
        "    if not np.isnan(resistance):\n",
        "        sl = min(resistance + atr_buffer, sl_cap)\n",
        "    else:\n",
        "        sl = sl_cap\n",
        "\n",
        "    tp_floor = entry_price - (tp_atr_mult * atr_buffer)\n",
        "    if not np.isnan(support):\n",
        "        tp = max(support + (0.2 * atr_buffer), tp_floor)\n",
        "    else:\n",
        "        tp = tp_floor\n",
        "\n",
        "    if tp >= entry_price:\n",
        "        tp = entry_price * 0.995\n",
        "    if sl <= entry_price:\n",
        "        sl = entry_price * 1.005\n",
        "\n",
        "    return tp, sl, \"TP/SL dari resistance-support + buffer ATR (skenario short)\"\n",
        "\n",
        "\n",
        "def suggest_entry_range(signal: str, last_close: float, support: float, resistance: float, atr_value: float | None, interval: str = \"1d\"):\n",
        "    \"\"\"Saran range entry realistis berbasis ATR + support/resistance + konteks sinyal.\"\"\"\n",
        "    atr_buffer = 0.35 * atr_value if atr_value is not None and not np.isnan(atr_value) and atr_value > 0 else last_close * 0.004\n",
        "    intraday = interval in {\"1h\", \"60m\", \"30m\", \"15m\", \"5m\", \"1m\"}\n",
        "    pullback_mult = 0.8 if intraday else 1.1\n",
        "    breakout_mult = 0.6 if intraday else 0.9\n",
        "\n",
        "    if signal == \"BELI\":\n",
        "        # Entry ideal saat pullback mendekati support atau area diskon dari harga terakhir.\n",
        "        base_low = last_close - (pullback_mult * atr_buffer)\n",
        "        base_high = last_close + (0.25 * atr_buffer)\n",
        "\n",
        "        if not np.isnan(support):\n",
        "            low = max(support + (0.05 * atr_buffer), base_low)\n",
        "        else:\n",
        "            low = base_low\n",
        "\n",
        "        if not np.isnan(resistance):\n",
        "            high_cap = resistance - (0.2 * atr_buffer)\n",
        "            high = min(base_high, high_cap)\n",
        "        else:\n",
        "            high = base_high\n",
        "\n",
        "        if low >= high:\n",
        "            low = last_close * 0.997\n",
        "            high = last_close * 1.003\n",
        "\n",
        "        return low, high, \"Entry BUY disarankan saat pullback (dekat support/area diskon ATR)\"\n",
        "\n",
        "    if signal == \"JUAL\":\n",
        "        # Entry ideal saat rebound mendekati resistance atau area premium dari harga terakhir.\n",
        "        base_low = last_close - (0.25 * atr_buffer)\n",
        "        base_high = last_close + (breakout_mult * atr_buffer)\n",
        "\n",
        "        if not np.isnan(support):\n",
        "            low_floor = support + (0.2 * atr_buffer)\n",
        "            low = max(base_low, low_floor)\n",
        "        else:\n",
        "            low = base_low\n",
        "\n",
        "        if not np.isnan(resistance):\n",
        "            high = min(resistance - (0.05 * atr_buffer), base_high)\n",
        "        else:\n",
        "            high = base_high\n",
        "\n",
        "        if low >= high:\n",
        "            low = last_close * 0.997\n",
        "            high = last_close * 1.003\n",
        "\n",
        "        return low, high, \"Entry SELL disarankan saat rebound (dekat resistance/area premium ATR)\"\n",
        "\n",
        "    neutral_low = last_close - (0.5 * atr_buffer)\n",
        "    neutral_high = last_close + (0.5 * atr_buffer)\n",
        "    return neutral_low, neutral_high, \"Mode TAHAN: entry agresif tidak disarankan, hanya range observasi\"\n",
        "\n",
        "\n",
        "def forecast_next_periods(last_close: float, expected_return: float, start_date: pd.Timestamp, periods: int, interval: str,\n",
        "                          return_history: pd.Series, prob_up: float) -> pd.DataFrame:\n",
        "    \"\"\"Forecast path yang lebih realistis: tidak pakai return konstan, tapi bootstrap return historis kondisional.\"\"\"\n",
        "    if interval in {\"1h\", \"60m\"}:\n",
        "        future_index = generate_next_bej_session_timestamps(start_ts=start_date, periods=periods)\n",
        "        price_col = \"Predicted_Close_1h\"\n",
        "        ret_col = \"Simulated_Return\"\n",
        "    else:\n",
        "        future_index = pd.bdate_range(start=start_date + pd.Timedelta(days=1), periods=periods)\n",
        "        price_col = \"Predicted_Close_1d\"\n",
        "        ret_col = \"Simulated_Return\"\n",
        "\n",
        "    hist = return_history.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "    if len(hist) < 10:\n",
        "        simulated_returns = np.full(periods, expected_return)\n",
        "    else:\n",
        "        up_hist = hist[hist > 0]\n",
        "        down_hist = hist[hist <= 0]\n",
        "\n",
        "        if len(up_hist) == 0:\n",
        "            up_hist = hist\n",
        "        if len(down_hist) == 0:\n",
        "            down_hist = hist\n",
        "\n",
        "        rng = np.random.default_rng(SEED)\n",
        "        simulated_returns = []\n",
        "        local_prob_up = min(max(prob_up, 0.05), 0.95)\n",
        "\n",
        "        for i in range(periods):\n",
        "            pick_up = rng.random() < local_prob_up\n",
        "            if pick_up:\n",
        "                r = float(rng.choice(up_hist.values))\n",
        "            else:\n",
        "                r = float(rng.choice(down_hist.values))\n",
        "\n",
        "            # clamp agar tidak ekstrem dan tambah sedikit mean-reversion ke expected return\n",
        "            r = float(np.clip(r, -0.04, 0.04))\n",
        "            r = 0.7 * r + 0.3 * expected_return\n",
        "            simulated_returns.append(r)\n",
        "\n",
        "            # update probabilitas secara ringan supaya jalur tidak monoton\n",
        "            local_prob_up = 0.8 * local_prob_up + 0.2 * (0.5 + np.tanh(r * 20) * 0.15)\n",
        "            local_prob_up = min(max(local_prob_up, 0.2), 0.8)\n",
        "\n",
        "        simulated_returns = np.array(simulated_returns)\n",
        "\n",
        "    prices, price = [], float(last_close)\n",
        "    for r in simulated_returns:\n",
        "        price = price * (1 + r)\n",
        "        prices.append(price)\n",
        "\n",
        "    out = pd.DataFrame({\"Date\": future_index, price_col: prices, ret_col: simulated_returns})\n",
        "    out[\"Expected_Return_Base\"] = expected_return\n",
        "    return out\n",
        "\n",
        "\n",
        "def prepare_dataset(interval: str) -> tuple[pd.DataFrame, str, dict]:\n",
        "    if interval in {\"1h\", \"60m\", \"30m\", \"15m\", \"5m\", \"1m\"}:\n",
        "        periods_to_try = [INTRADAY_PERIOD] + [p for p in INTRADAY_FALLBACK_PERIODS if p != INTRADAY_PERIOD]\n",
        "        for period in periods_to_try:\n",
        "            raw = download_data(SYMBOL, interval, START, END, period)\n",
        "            raw = apply_as_of_cutoff(raw, AS_OF_DATE)\n",
        "            if raw.empty:\n",
        "                continue\n",
        "            base = raw[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]].copy()\n",
        "            feat = build_features(base, interval)\n",
        "            if feat.empty:\n",
        "                continue\n",
        "            min_required = MIN_ROWS_INTRADAY if interval in {\"1h\", \"60m\", \"30m\", \"15m\", \"5m\", \"1m\"} else MIN_ROWS_AFTER_FEATURES\n",
        "            if len(feat) >= min_required:\n",
        "                feat, info = add_market_context_features(feat, interval, START, END, period, AS_OF_DATE)\n",
        "                return feat, period, info\n",
        "        # fallback: pakai dataset terbaik yang masih memungkinkan split\n",
        "        best_feat, best_period = None, None\n",
        "        for period in periods_to_try:\n",
        "            raw = download_data(SYMBOL, interval, START, END, period)\n",
        "            raw = apply_as_of_cutoff(raw, AS_OF_DATE)\n",
        "            if raw.empty:\n",
        "                continue\n",
        "            base = raw[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]].copy()\n",
        "            feat = build_features(base, interval)\n",
        "            if feat.empty:\n",
        "                continue\n",
        "            if best_feat is None or len(feat) > len(best_feat):\n",
        "                best_feat, best_period = feat, period\n",
        "        if best_feat is not None and len(best_feat) >= 12:\n",
        "            best_feat, info = add_market_context_features(best_feat, interval, START, END, best_period, AS_OF_DATE)\n",
        "            return best_feat, f\"{best_period} (best-effort)\", info\n",
        "        raise ValueError(\n",
        "            f\"Data intraday terlalu sedikit setelah feature engineering. Coba period lebih besar. Tried={periods_to_try}\"\n",
        "        )\n",
        "\n",
        "    raw = download_data(SYMBOL, interval, START, END, INTRADAY_PERIOD)\n",
        "    raw = apply_as_of_cutoff(raw, AS_OF_DATE)\n",
        "    if raw.empty:\n",
        "        raise ValueError(\n",
        "            \"Data harian kosong dari Yahoo Finance. Cek SYMBOL/INTERVAL, atau perlebar START/END.\"\n",
        "        )\n",
        "\n",
        "    base = raw[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]].copy()\n",
        "    feat = build_features(base, interval)\n",
        "    if feat.empty or len(feat) < MIN_ROWS_AFTER_FEATURES:\n",
        "        raise ValueError(\n",
        "            f\"Data harian terlalu sedikit setelah feature engineering: {len(feat)} baris. \"\n",
        "            \"Coba perlebar START/END atau ganti saham dengan histori lebih lengkap.\"\n",
        "        )\n",
        "\n",
        "    feat, info = add_market_context_features(feat, interval, START, END, INTRADAY_PERIOD, AS_OF_DATE)\n",
        "    if feat.empty:\n",
        "        raise ValueError(\n",
        "            \"Semua baris hilang setelah penggabungan fitur konteks market. \"\n",
        "            \"Coba nonaktifkan sumber eksternal yang bermasalah atau ganti simbol.\"\n",
        "        )\n",
        "    return feat, \"start/end\", info\n",
        "\n",
        "\n",
        "def main():\n",
        "    mode_config = get_runtime_mode_config()\n",
        "    interval = mode_config[\"interval\"]\n",
        "\n",
        "    df, data_window_used, market_info = prepare_dataset(interval)\n",
        "    train_df, val_df, test_df = split_time_series(df)\n",
        "    feature_cols = [c for c in df.columns if c != \"Target\"]\n",
        "\n",
        "    X_train, y_train = train_df[feature_cols], train_df[\"Target\"].to_numpy()\n",
        "    X_val, y_val = val_df[feature_cols], val_df[\"Target\"].to_numpy()\n",
        "    X_test, y_test = test_df[feature_cols], test_df[\"Target\"].to_numpy()\n",
        "\n",
        "    X_train = replace_inf_with_nan(X_train)\n",
        "    X_val = replace_inf_with_nan(X_val)\n",
        "    X_test = replace_inf_with_nan(X_test)\n",
        "\n",
        "    candidates = get_model_candidates()\n",
        "    evaluations = [evaluate_model(name, model, X_train, y_train, X_val, y_val) for name, model in candidates.items()]\n",
        "    best = max(evaluations, key=lambda x: (x[\"val_bacc\"], np.nan_to_num(x[\"val_auc\"], nan=-1.0)))\n",
        "\n",
        "    best_model = best[\"model\"]\n",
        "    best_threshold = best[\"threshold\"]\n",
        "\n",
        "    probs_up = np.nan_to_num(best_model.predict_proba(X_test)[:, 1], nan=0.5, posinf=1.0, neginf=0.0)\n",
        "    probs_down = 1 - probs_up\n",
        "    preds = (probs_up >= best_threshold).astype(int)\n",
        "\n",
        "    print(f\"Mode trading : {mode_config['name']} ({mode_config['horizon_note']})\")\n",
        "    print(f\"Mode interval: {interval}\")\n",
        "    print(f\"Data window used: {data_window_used}\")\n",
        "    print(f\"As-of cutoff: {AS_OF_DATE if AS_OF_DATE else 'latest available'}\")\n",
        "    print(f\"IHSG context used: {market_info.get('ihsg_used')}\")\n",
        "    print(f\"Global markets used: {market_info.get('global_markets_used', 0)}/{len(GLOBAL_INDEX_TICKERS)}\")\n",
        "    print(f\"Commodities used  : {market_info.get('commodities_used', 0)}/{len(COMMODITY_TICKERS)}\")\n",
        "    print(f\"INDO VIX source : {market_info.get('indovix_symbol') if market_info.get('indovix_symbol') else 'not found (filled neutral)'}\")\n",
        "    print(f\"USD/IDR context: {market_info.get('currency_used')}\")\n",
        "    print(f\"Timestamp aligned: {market_info.get('timestamps_aligned')}\")\n",
        "    print(f\"VIX fear rules  : spike>={VIX_SPIKE_THRESHOLD:.2%}, high_level>={VIX_HIGH_LEVEL}\")\n",
        "    print(f\"BEI sessions    : {SESSION1_START}-{SESSION1_END} & {SESSION2_START}-{SESSION2_END} ({JKT_TZ})\")\n",
        "    print(\"Model candidates (validation):\")\n",
        "    for ev in evaluations:\n",
        "        auc_text = \"nan\" if np.isnan(ev[\"val_auc\"]) else f\"{ev['val_auc']:.4f}\"\n",
        "        print(\n",
        "            f\"- {ev['name']}: AUC={auc_text}, \"\n",
        "            f\"BalancedAcc={ev['val_bacc']:.4f}, Acc={ev['val_acc']:.4f}, Threshold={ev['threshold']:.2f}\"\n",
        "        )\n",
        "\n",
        "    print(f\"\\nModel terpilih: {best['name']}\")\n",
        "    print(f\"Best threshold (validation): {best_threshold:.2f}\")\n",
        "    print(f\"Test accuracy: {accuracy_score(y_test, preds):.4f}\")\n",
        "    print(f\"Test balanced accuracy: {balanced_accuracy_score(y_test, preds):.4f}\")\n",
        "    print(f\"Test ROC-AUC: {safe_auc(y_test, probs_up):.4f}\" if len(np.unique(y_test)) > 1 else \"Test ROC-AUC: nan\")\n",
        "    print(confusion_matrix(y_test, preds))\n",
        "    print(classification_report(y_test, preds, digits=4, zero_division=0))\n",
        "\n",
        "    result = pd.DataFrame(\n",
        "        {\n",
        "            \"Date\": test_df.index,\n",
        "            \"Close\": test_df[\"Close\"].to_numpy().reshape(-1),\n",
        "            \"Prob_Naik\": probs_up,\n",
        "            \"Prob_Turun\": probs_down,\n",
        "            \"Aktual\": np.where(y_test == 1, \"NAIK\", \"TURUN\"),\n",
        "            \"INDOVIX_Level\": test_df[\"INDOVIX_Level\"].to_numpy().reshape(-1) if \"INDOVIX_Level\" in test_df.columns else np.nan,\n",
        "            \"INDOVIX_Change_1\": test_df[\"INDOVIX_Change_1\"].to_numpy().reshape(-1) if \"INDOVIX_Change_1\" in test_df.columns else np.nan,\n",
        "            \"Buy_Volume_Anomaly\": test_df[\"Buy_Volume_Anomaly\"].to_numpy().reshape(-1) if \"Buy_Volume_Anomaly\" in test_df.columns else np.nan,\n",
        "            \"Sell_Volume_Anomaly\": test_df[\"Sell_Volume_Anomaly\"].to_numpy().reshape(-1) if \"Sell_Volume_Anomaly\" in test_df.columns else np.nan,\n",
        "            \"Net_Volume_Anomaly\": test_df[\"Net_Volume_Anomaly\"].to_numpy().reshape(-1) if \"Net_Volume_Anomaly\" in test_df.columns else np.nan,\n",
        "            \"Volume_Anomaly_Spike\": test_df[\"Volume_Anomaly_Spike\"].to_numpy().reshape(-1) if \"Volume_Anomaly_Spike\" in test_df.columns else 0,\n",
        "            \"Support_Level\": test_df[\"Support_Level\"].to_numpy().reshape(-1) if \"Support_Level\" in test_df.columns else np.nan,\n",
        "            \"Resistance_Level\": test_df[\"Resistance_Level\"].to_numpy().reshape(-1) if \"Resistance_Level\" in test_df.columns else np.nan,\n",
        "        }\n",
        "    )\n",
        "    result[\"Signal_Dasar\"] = result[\"Prob_Naik\"].apply(lambda p: decide_signal(float(p), best_threshold))\n",
        "    result[\"Catatan_VolumeFlow\"] = result.apply(\n",
        "        lambda r: interpret_volume_flow(\n",
        "            float(r[\"Net_Volume_Anomaly\"]) if \"Net_Volume_Anomaly\" in result.columns else np.nan,\n",
        "            float(r[\"Buy_Volume_Anomaly\"]) if \"Buy_Volume_Anomaly\" in result.columns else np.nan,\n",
        "            float(r[\"Sell_Volume_Anomaly\"]) if \"Sell_Volume_Anomaly\" in result.columns else np.nan,\n",
        "        ),\n",
        "        axis=1,\n",
        "    )\n",
        "\n",
        "    result[[\"Signal_Akhir\", \"Catatan_VIX\"]] = result.apply(\n",
        "        lambda r: pd.Series(\n",
        "            adjust_signal_with_vix_fear(\n",
        "                signal=r[\"Signal_Dasar\"],\n",
        "                prob_up=float(r[\"Prob_Naik\"]),\n",
        "                vix_level=float(r[\"INDOVIX_Level\"]) if \"INDOVIX_Level\" in result.columns else np.nan,\n",
        "                vix_change_1=float(r[\"INDOVIX_Change_1\"]) if \"INDOVIX_Change_1\" in result.columns else np.nan,\n",
        "            )\n",
        "        ),\n",
        "        axis=1,\n",
        "    )\n",
        "\n",
        "    result_display = result[\n",
        "        [\n",
        "            \"Date\",\n",
        "            \"Close\",\n",
        "            \"Prob_Naik\",\n",
        "            \"Prob_Turun\",\n",
        "            \"Aktual\",\n",
        "            \"INDOVIX_Level\",\n",
        "            \"Signal_Dasar\",\n",
        "            \"Catatan_VolumeFlow\",\n",
        "            \"Signal_Akhir\",\n",
        "        ]\n",
        "    ]\n",
        "\n",
        "    print(\"\\nContoh output (10 baris terakhir):\")\n",
        "    print(result_display.tail(10).to_string(index=False))\n",
        "\n",
        "    latest_row = replace_inf_with_nan(df[feature_cols].tail(1))\n",
        "    prob_up_now = float(np.nan_to_num(best_model.predict_proba(latest_row)[:, 1], nan=0.5, posinf=1.0, neginf=0.0)[0])\n",
        "    prob_down_now = 1 - prob_up_now\n",
        "    prob_with_ihsg, delta_ihsg = estimate_ihsg_influence_on_latest(best_model, latest_row)\n",
        "    signal_now_base = decide_signal(prob_up_now, best_threshold)\n",
        "    vix_level_now = float(df[\"INDOVIX_Level\"].iloc[-1]) if \"INDOVIX_Level\" in df.columns else np.nan\n",
        "    vix_change_now = float(df[\"INDOVIX_Change_1\"].iloc[-1]) if \"INDOVIX_Change_1\" in df.columns else np.nan\n",
        "    buy_vol_anom_now = float(df[\"Buy_Volume_Anomaly\"].iloc[-1]) if \"Buy_Volume_Anomaly\" in df.columns else np.nan\n",
        "    sell_vol_anom_now = float(df[\"Sell_Volume_Anomaly\"].iloc[-1]) if \"Sell_Volume_Anomaly\" in df.columns else np.nan\n",
        "    net_vol_anom_now = float(df[\"Net_Volume_Anomaly\"].iloc[-1]) if \"Net_Volume_Anomaly\" in df.columns else np.nan\n",
        "    vol_flow_note = interpret_volume_flow(net_vol_anom_now, buy_vol_anom_now, sell_vol_anom_now)\n",
        "    support_now = float(df[\"Support_Level\"].iloc[-1]) if \"Support_Level\" in df.columns else np.nan\n",
        "    resistance_now = float(df[\"Resistance_Level\"].iloc[-1]) if \"Resistance_Level\" in df.columns else np.nan\n",
        "    sr_note, sr_bias = interpret_sr_breakout(float(df[\"Close\"].iloc[-1]), support_now, resistance_now)\n",
        "    signal_now, vix_note = adjust_signal_with_vix_fear(signal_now_base, prob_up_now, vix_level_now, vix_change_now)\n",
        "    if sr_bias == -1 and signal_now == \"BELI\":\n",
        "        signal_now = \"TAHAN\"\n",
        "    if sr_bias == 1 and signal_now == \"JUAL\":\n",
        "        signal_now = \"TAHAN\"\n",
        "    atr_now = float(df[\"ATR\"].iloc[-1]) if \"ATR\" in df.columns else np.nan\n",
        "    stoploss_price, stoploss_pct, stoploss_note = suggest_stoploss(\n",
        "        signal=signal_now,\n",
        "        last_close=float(df[\"Close\"].iloc[-1]),\n",
        "        atr_value=atr_now,\n",
        "        prob_up=prob_up_now,\n",
        "    )\n",
        "    tp_price, sl_price_sr, tp_sl_note = suggest_tp_sl_from_sr(\n",
        "        signal=signal_now,\n",
        "        entry_price=float(df[\"Close\"].iloc[-1]),\n",
        "        support=support_now,\n",
        "        resistance=resistance_now,\n",
        "        atr_value=atr_now,\n",
        "        interval=interval,\n",
        "    )\n",
        "    entry_low, entry_high, entry_note = suggest_entry_range(\n",
        "        signal=signal_now,\n",
        "        last_close=float(df[\"Close\"].iloc[-1]),\n",
        "        support=support_now,\n",
        "        resistance=resistance_now,\n",
        "        atr_value=atr_now,\n",
        "        interval=interval,\n",
        "    )\n",
        "\n",
        "    print(\"\\nSignal saat ini:\")\n",
        "    print(f\"Timestamp terakhir   : {df.index[-1]}\")\n",
        "    print(f\"Prob_Naik saat ini   : {prob_up_now:.4f}\")\n",
        "    print(f\"Prob_Turun saat ini  : {prob_down_now:.4f}\")\n",
        "    print(f\"IHSG impact (delta)  : {delta_ihsg:+.4f} pada Prob_Naik (vs IHSG=0)\")\n",
        "    print(f\"Signal dasar         : {signal_now_base}\")\n",
        "    print(f\"INDO VIX level/change: {vix_level_now:.4f} / {vix_change_now:.4f}\")\n",
        "    print(f\"Signal saat ini      : {signal_now}\")\n",
        "    print(f\"Catatan INDO VIX     : {vix_note}\")\n",
        "    print(f\"Volume anomaly (B/S/N): {buy_vol_anom_now:.4f} / {sell_vol_anom_now:.4f} / {net_vol_anom_now:.4f}\")\n",
        "    print(f\"Catatan volume flow  : {vol_flow_note}\")\n",
        "    print(f\"Support/Resistance   : {support_now:.2f} / {resistance_now:.2f}\")\n",
        "    print(f\"Saran range entry    : {entry_low:.2f} - {entry_high:.2f}\")\n",
        "    print(f\"Catatan entry range  : {entry_note}\")\n",
        "    print(f\"Catatan breakout SR  : {sr_note}\")\n",
        "    if stoploss_price is not None:\n",
        "        print(f\"Stop-loss saran (ATR): {stoploss_price:.2f} ({stoploss_pct:.2f}%)\")\n",
        "    print(f\"Catatan stop-loss    : {stoploss_note}\")\n",
        "    if tp_price is not None and sl_price_sr is not None:\n",
        "        rr = abs((tp_price - float(df[\"Close\"].iloc[-1])) / (float(df[\"Close\"].iloc[-1]) - sl_price_sr)) if signal_now == \"BELI\" and float(df[\"Close\"].iloc[-1]) != sl_price_sr else None\n",
        "        if signal_now == \"JUAL\":\n",
        "            rr = abs((float(df[\"Close\"].iloc[-1]) - tp_price) / (sl_price_sr - float(df[\"Close\"].iloc[-1]))) if sl_price_sr != float(df[\"Close\"].iloc[-1]) else None\n",
        "        print(f\"Take-profit (SR)     : {tp_price:.2f}\")\n",
        "        print(f\"Stop-loss (SR)       : {sl_price_sr:.2f}\")\n",
        "        if rr is not None and np.isfinite(rr):\n",
        "            print(f\"Risk/Reward approx   : 1:{rr:.2f}\")\n",
        "    print(f\"Catatan TP/SL SR     : {tp_sl_note}\")\n",
        "\n",
        "    expected_ret = estimate_expected_return(prob_up_now, train_df[\"Return\"])\n",
        "\n",
        "    forecast = forecast_next_periods(\n",
        "        last_close=float(df[\"Close\"].iloc[-1]),\n",
        "        expected_return=expected_ret,\n",
        "        start_date=df.index[-1],\n",
        "        periods=mode_config[\"forecast_periods\"],\n",
        "        interval=interval,\n",
        "        return_history=train_df[\"Return\"],\n",
        "        prob_up=prob_up_now,\n",
        "    )\n",
        "    print(f\"\\n{mode_config['forecast_label']}:\")\n",
        "    print(forecast.to_string(index=False))"
      ],
      "metadata": {
        "id": "-kCMIk9TFCm9"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRo_zVMVFvCC",
        "outputId": "0f422584-6af5-4370-efb3-eb32862fb85a"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['^JKVIX']: YFPricesMissingError('possibly delisted; no price data found  (period=720d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['JKVIX']: YFPricesMissingError('possibly delisted; no price data found  (period=720d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['VIX.JK']: YFPricesMissingError('possibly delisted; no price data found  (period=720d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "/tmp/ipython-input-466/2561276555.py:182: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
            "  market_ret_1 = market_close.pct_change().replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
            "/tmp/ipython-input-466/2561276555.py:183: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
            "  market_ret_5 = market_close.pct_change(5).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mode trading : harian (intraday/day-trading)\n",
            "Mode interval: 1h\n",
            "Data window used: 720d\n",
            "As-of cutoff: 2026-02-23\n",
            "IHSG context used: True\n",
            "Global markets used: 2/5\n",
            "Commodities used  : 2/2\n",
            "INDO VIX source : ^VIX\n",
            "USD/IDR context: True\n",
            "Timestamp aligned: True\n",
            "VIX fear rules  : spike>=4.00%, high_level>=25.0\n",
            "BEI sessions    : 09:00:00-12:00:00 & 13:30:00-16:00:00 (Asia/Jakarta)\n",
            "Model candidates (validation):\n",
            "- HistGradientBoosting: AUC=0.4768, BalancedAcc=0.5246, Acc=0.5046, Threshold=0.34\n",
            "- ExtraTrees: AUC=0.5572, BalancedAcc=0.5837, Acc=0.4862, Threshold=0.51\n",
            "- LogisticRegression: AUC=0.5207, BalancedAcc=0.5272, Acc=0.4679, Threshold=0.69\n",
            "- XGBoost: AUC=0.5207, BalancedAcc=0.5819, Acc=0.5505, Threshold=0.31\n",
            "\n",
            "Model terpilih: ExtraTrees\n",
            "Best threshold (validation): 0.51\n",
            "Test accuracy: 0.4312\n",
            "Test balanced accuracy: 0.4896\n",
            "Test ROC-AUC: 0.5304\n",
            "[[ 0 61]\n",
            " [ 1 47]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0000    0.0000    0.0000        61\n",
            "           1     0.4352    0.9792    0.6026        48\n",
            "\n",
            "    accuracy                         0.4312       109\n",
            "   macro avg     0.2176    0.4896    0.3013       109\n",
            "weighted avg     0.1916    0.4312    0.2653       109\n",
            "\n",
            "\n",
            "Contoh output (10 baris terakhir):\n",
            "                     Date  Close  Prob_Naik  Prob_Turun Aktual  INDOVIX_Level Signal_Dasar                        Catatan_VolumeFlow Signal_Akhir\n",
            "2026-02-20 09:00:00+07:00  288.0   0.602536    0.397464   NAIK      20.379999         BELI               Volume flow netral/campuran         BELI\n",
            "2026-02-20 11:00:00+07:00  288.0   0.555502    0.444498  TURUN      20.379999        TAHAN               Volume flow netral/campuran        TAHAN\n",
            "2026-02-20 14:00:00+07:00  284.0   0.631520    0.368480  TURUN      20.379999         BELI SELL PRESSURE DOMINAN (anomali jual kuat)         BELI\n",
            "2026-02-20 15:00:00+07:00  284.0   0.625011    0.374989  TURUN      19.920000         BELI SELL PRESSURE DOMINAN (anomali jual kuat)         BELI\n",
            "2026-02-20 16:00:00+07:00  284.0   0.575541    0.424459   NAIK      20.000000         BELI               Volume flow netral/campuran         BELI\n",
            "2026-02-23 09:00:00+07:00  288.0   0.614072    0.385928   NAIK      20.000000         BELI               Volume flow netral/campuran         BELI\n",
            "2026-02-23 11:00:00+07:00  296.0   0.579530    0.420470   NAIK      20.000000         BELI  BUY PRESSURE DOMINAN (anomali beli kuat)         BELI\n",
            "2026-02-23 14:00:00+07:00  304.0   0.584999    0.415001   NAIK      20.000000         BELI  BUY PRESSURE DOMINAN (anomali beli kuat)         BELI\n",
            "2026-02-23 15:00:00+07:00  310.0   0.589011    0.410989  TURUN      20.410000         BELI               Volume flow netral/campuran         BELI\n",
            "2026-02-23 16:00:00+07:00  310.0   0.609597    0.390403  TURUN      19.910000         BELI               Volume flow netral/campuran         BELI\n",
            "\n",
            "Signal saat ini:\n",
            "Timestamp terakhir   : 2026-02-23 16:00:00+07:00\n",
            "Prob_Naik saat ini   : 0.6096\n",
            "Prob_Turun saat ini  : 0.3904\n",
            "IHSG impact (delta)  : -0.0055 pada Prob_Naik (vs IHSG=0)\n",
            "Signal dasar         : BELI\n",
            "INDO VIX level/change: 19.9100 / -0.0245\n",
            "Signal saat ini      : BELI\n",
            "Catatan INDO VIX     : Tidak ada penyesuaian signal dari INDO VIX\n",
            "Volume anomaly (B/S/N): -0.5319 / -0.4127 / -0.1192\n",
            "Catatan volume flow  : Volume flow netral/campuran\n",
            "Support/Resistance   : 282.00 / 312.00\n",
            "Saran range entry    : 307.81 - 310.69\n",
            "Catatan entry range  : Entry BUY disarankan saat pullback (dekat support/area diskon ATR)\n",
            "Catatan breakout SR  : Masih di dalam range support-resistance\n",
            "Stop-loss saran (ATR): 297.06 (4.18%)\n",
            "Catatan stop-loss    : ATR x 1.65 di bawah harga masuk\n",
            "Take-profit (SR)     : 311.22\n",
            "Stop-loss (SR)       : 305.30\n",
            "Risk/Reward approx   : 1:0.26\n",
            "Catatan TP/SL SR     : TP/SL dari resistance-support + buffer ATR (skenario long)\n",
            "\n",
            "Prediksi harga 24 jam ke depan (hourly):\n",
            "                     Date  Predicted_Close_1h  Simulated_Return  Expected_Return_Base\n",
            "2026-02-24 09:00:00+07:00          307.313397         -0.008666              0.011574\n",
            "2026-02-24 10:00:00+07:00          308.380471          0.003472              0.011574\n",
            "2026-02-24 11:00:00+07:00          309.451250          0.003472              0.011574\n",
            "2026-02-24 12:00:00+07:00          310.525748          0.003472              0.011574\n",
            "2026-02-24 14:00:00+07:00          302.909255         -0.024528              0.011574\n",
            "2026-02-24 15:00:00+07:00          305.757956          0.009404              0.011574\n",
            "2026-02-24 16:00:00+07:00          315.380852          0.031472              0.011574\n",
            "2026-02-25 09:00:00+07:00          316.475939          0.003472              0.011574\n",
            "2026-02-25 10:00:00+07:00          317.574828          0.003472              0.011574\n",
            "2026-02-25 11:00:00+07:00          321.946685          0.013766              0.011574\n",
            "2026-02-25 12:00:00+07:00          327.316696          0.016680              0.011574\n",
            "2026-02-25 14:00:00+07:00          329.770018          0.007495              0.011574\n",
            "2026-02-25 15:00:00+07:00          326.640271         -0.009491              0.011574\n",
            "2026-02-25 16:00:00+07:00          327.774453          0.003472              0.011574\n",
            "2026-02-26 09:00:00+07:00          333.324922          0.016934              0.011574\n",
            "2026-02-26 10:00:00+07:00          333.093461         -0.000694              0.011574\n",
            "2026-02-26 11:00:00+07:00          334.250051          0.003472              0.011574\n",
            "2026-02-26 12:00:00+07:00          339.998402          0.017198              0.011574\n",
            "2026-02-26 14:00:00+07:00          350.698922          0.031472              0.011574\n",
            "2026-02-26 15:00:00+07:00          351.916643          0.003472              0.011574\n",
            "2026-02-26 16:00:00+07:00          348.576709         -0.009491              0.011574\n",
            "2026-02-27 09:00:00+07:00          359.547208          0.031472              0.011574\n",
            "2026-02-27 10:00:00+07:00          365.635710          0.016934              0.011574\n",
            "2026-02-27 11:00:00+07:00          371.587216          0.016277              0.011574\n"
          ]
        }
      ]
    }
  ]
}