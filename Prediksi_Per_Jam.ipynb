{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHwHJJhPfzT37Uof+1yLuP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndikaPutra509/Prediksi-Saham/blob/PrediksiSaham/Prediksi_Per_Jam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXtNC6XUEuCw",
        "outputId": "9ae4257e-2705-4836-c6ac-c01eb04f3733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ta\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ta\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    f1_score,\n",
        "    balanced_accuracy_score,\n",
        "    accuracy_score,\n",
        ")\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "fjqp8UPuE79g"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYMBOL = \"BUMI.JK\"\n",
        "INTERVAL = \"1h\"\n",
        "START = \"2013-01-01\"\n",
        "INTRADAY_PERIOD = \"3d\"\n",
        "INTRADAY_FALLBACK_PERIODS = [\"3d\", \"5d\", \"10d\", \"30d\", \"60d\", \"180d\"]\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.15\n",
        "HOLD_BAND = 0.05\n",
        "MIN_ROWS_AFTER_FEATURES = 40\n",
        "AS_OF_DATE = None  # contoh: \"2026-02-18\" atau \"2026-02-18 15:00:00\""
      ],
      "metadata": {
        "id": "XBU6axLME_SX"
      },
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = df.columns.get_level_values(0)\n",
        "    return df"
      ],
      "metadata": {
        "id": "-kCMIk9TFCm9"
      },
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_inf_with_nan(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    num_cols = out.select_dtypes(include=[np.number]).columns\n",
        "    out.loc[:, num_cols] = out.loc[:, num_cols].replace([np.inf, -np.inf], np.nan)\n",
        "    return out"
      ],
      "metadata": {
        "id": "hzg1ZlN4FGab"
      },
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_data(symbol: str, interval: str, start: str, end: str, intraday_period: str) -> pd.DataFrame:\n",
        "    if interval in {\"1h\", \"60m\", \"30m\", \"15m\", \"5m\", \"1m\"}:\n",
        "        raw = yf.download(symbol, period=intraday_period, interval=interval, auto_adjust=True, progress=True)\n",
        "    else:\n",
        "        raw = yf.download(symbol, start=start, end=end, interval=interval, auto_adjust=True, progress=True)\n",
        "    return normalize_columns(raw)"
      ],
      "metadata": {
        "id": "N7UdRst2FLF4"
      },
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_as_of_cutoff(df: pd.DataFrame, as_of_date: str | None) -> pd.DataFrame:\n",
        "    if as_of_date is None:\n",
        "        return df\n",
        "\n",
        "    cutoff = pd.to_datetime(as_of_date)\n",
        "\n",
        "    # Jika user isi tanggal tanpa jam, anggap sampai akhir hari itu\n",
        "    if len(str(as_of_date)) <= 10:\n",
        "        cutoff = cutoff + pd.Timedelta(days=1) - pd.Timedelta(microseconds=1)\n",
        "\n",
        "    idx = df.index\n",
        "    if isinstance(idx, pd.DatetimeIndex) and idx.tz is not None and cutoff.tzinfo is None:\n",
        "        cutoff = cutoff.tz_localize(idx.tz)\n",
        "\n",
        "    return df.loc[df.index <= cutoff].copy()"
      ],
      "metadata": {
        "id": "5U_PtLUZUWiC"
      },
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    close = out[\"Close\"]\n",
        "    high = out[\"High\"]\n",
        "    low = out[\"Low\"]\n",
        "    volume = out[\"Volume\"]\n",
        "\n",
        "    out[\"RSI\"] = ta.momentum.RSIIndicator(close).rsi()\n",
        "    out[\"MA20\"] = close.rolling(20).mean()\n",
        "    out[\"MA50\"] = close.rolling(50).mean()\n",
        "    out[\"MACD\"] = ta.trend.MACD(close).macd()\n",
        "\n",
        "    bb = ta.volatility.BollingerBands(close)\n",
        "    out[\"BB_high\"] = bb.bollinger_hband()\n",
        "    out[\"BB_low\"] = bb.bollinger_lband()\n",
        "    out[\"BB_width\"] = out[\"BB_high\"] - out[\"BB_low\"]\n",
        "\n",
        "    out[\"ATR\"] = ta.volatility.AverageTrueRange(high, low, close).average_true_range()\n",
        "    out[\"OBV\"] = ta.volume.OnBalanceVolumeIndicator(close, volume).on_balance_volume()\n",
        "\n",
        "    out[\"Return\"] = close.pct_change()\n",
        "    out[\"Return_5\"] = close.pct_change(5)\n",
        "    out[\"Return_10\"] = close.pct_change(10)\n",
        "    out[\"Volatility_10\"] = out[\"Return\"].rolling(10).std()\n",
        "    out[\"Volatility_20\"] = out[\"Return\"].rolling(20).std()\n",
        "    out[\"Volume_Change\"] = volume.pct_change()\n",
        "\n",
        "    for lag in [1, 2, 3, 5, 10]:\n",
        "        out[f\"Lag_Return_{lag}\"] = out[\"Return\"].shift(lag)\n",
        "        out[f\"Lag_RSI_{lag}\"] = out[\"RSI\"].shift(lag)\n",
        "\n",
        "    out[\"Target\"] = (out[\"Return\"].shift(-1) > 0).astype(int)\n",
        "    out = replace_inf_with_nan(out)\n",
        "    return out.dropna().copy()"
      ],
      "metadata": {
        "id": "v6XqrNWhFNwo"
      },
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_auc(y_true: np.ndarray, probs: np.ndarray) -> float:\n",
        "    if len(np.unique(y_true)) < 2:\n",
        "        return float(\"nan\")\n",
        "    return roc_auc_score(y_true, probs)"
      ],
      "metadata": {
        "id": "yOs6KnRuPo_0"
      },
      "execution_count": 342,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_time_series(df: pd.DataFrame):\n",
        "    n = len(df)\n",
        "    if n < 12:\n",
        "        raise ValueError(f\"Data terlalu sedikit setelah feature engineering: {n} baris.\")\n",
        "\n",
        "    train_end = int(n * TRAIN_RATIO)\n",
        "    val_end = int(n * (TRAIN_RATIO + VAL_RATIO))\n",
        "\n",
        "    # pastikan masing-masing split minimal 1\n",
        "    train_end = max(1, min(train_end, n - 2))\n",
        "    val_end = max(train_end + 1, min(val_end, n - 1))\n",
        "\n",
        "    train_df = df.iloc[:train_end]\n",
        "    val_df = df.iloc[train_end:val_end]\n",
        "    test_df = df.iloc[val_end:]\n",
        "\n",
        "    if len(train_df) == 0 or len(val_df) == 0 or len(test_df) == 0:\n",
        "        raise ValueError(\n",
        "            f\"Split menghasilkan data kosong (train={len(train_df)}, val={len(val_df)}, test={len(test_df)}).\"\n",
        "        )\n",
        "    return train_df, val_df, test_df"
      ],
      "metadata": {
        "id": "utbd5IhzFQZh"
      },
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_threshold(y_true: np.ndarray, probs: np.ndarray) -> float:\n",
        "    if len(y_true) == 0 or len(np.unique(y_true)) < 2:\n",
        "        return 0.5\n",
        "\n",
        "    thresholds = np.arange(0.30, 0.71, 0.01)\n",
        "    best_t, best_bacc, best_f1 = 0.5, -1.0, -1.0\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        bacc = balanced_accuracy_score(y_true, preds)\n",
        "        f1 = f1_score(y_true, preds, zero_division=0)\n",
        "        if (bacc > best_bacc) or (np.isclose(bacc, best_bacc) and f1 > best_f1):\n",
        "            best_t, best_bacc, best_f1 = float(t), float(bacc), float(f1)\n",
        "    return best_t"
      ],
      "metadata": {
        "id": "87Mg919YFUHC"
      },
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decide_signal(prob_up: float, threshold: float, hold_band: float = HOLD_BAND) -> str:\n",
        "    upper = threshold + hold_band\n",
        "    lower = threshold - hold_band\n",
        "    if prob_up >= upper and prob_up > 0.5:\n",
        "        return \"BELI\"\n",
        "    if prob_up <= lower and prob_up < 0.5:\n",
        "        return \"JUAL\"\n",
        "    return \"TAHAN\""
      ],
      "metadata": {
        "id": "_CYmgyACFWqO"
      },
      "execution_count": 345,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_candidates():\n",
        "    return {\n",
        "        \"HistGradientBoosting\": HistGradientBoostingClassifier(\n",
        "            learning_rate=0.03,\n",
        "            max_depth=4,\n",
        "            max_iter=400,\n",
        "            min_samples_leaf=20,\n",
        "            random_state=SEED,\n",
        "        ),\n",
        "        \"RandomForest\": RandomForestClassifier(\n",
        "            n_estimators=600,\n",
        "            max_depth=8,\n",
        "            min_samples_leaf=8,\n",
        "            class_weight=\"balanced_subsample\",\n",
        "            random_state=SEED,\n",
        "            n_jobs=-1,\n",
        "        ),\n",
        "        \"LogisticRegression\": Pipeline(\n",
        "            steps=[\n",
        "                (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "                (\"scaler\", StandardScaler()),\n",
        "                (\"clf\", LogisticRegression(max_iter=2000, class_weight=\"balanced\", random_state=SEED)),\n",
        "            ]\n",
        "        ),\n",
        "    }"
      ],
      "metadata": {
        "id": "ClZYWfjuFc2m"
      },
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(name, model, X_train, y_train, X_val, y_val):\n",
        "    model.fit(X_train, y_train)\n",
        "    val_probs = np.nan_to_num(model.predict_proba(X_val)[:, 1], nan=0.5, posinf=1.0, neginf=0.0)\n",
        "    threshold = find_best_threshold(y_val, val_probs)\n",
        "    val_preds = (val_probs >= threshold).astype(int)\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"model\": model,\n",
        "        \"threshold\": threshold,\n",
        "        \"val_auc\": safe_auc(y_val, val_probs),\n",
        "        \"val_bacc\": balanced_accuracy_score(y_val, val_preds),\n",
        "        \"val_acc\": accuracy_score(y_val, val_preds),\n",
        "    }"
      ],
      "metadata": {
        "id": "4BfyZL4TFhyh"
      },
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_expected_return(prob_up: float, return_series: pd.Series) -> float:\n",
        "    up_returns = return_series[return_series > 0]\n",
        "    down_returns = return_series[return_series <= 0]\n",
        "    mean_up = float(up_returns.mean()) if len(up_returns) else 0.0\n",
        "    mean_down = float(down_returns.mean()) if len(down_returns) else 0.0\n",
        "    return (prob_up * mean_up) + ((1 - prob_up) * mean_down)"
      ],
      "metadata": {
        "id": "hz5LVlDkFllb"
      },
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def suggest_stoploss(signal: str, last_close: float, atr_value: float, prob_up: float, base_mult: float = 1.5):\n",
        "    if signal == \"TAHAN\":\n",
        "        return None, None, \"Tidak ada stop-loss karena sinyal TAHAN\"\n",
        "\n",
        "    confidence = abs(prob_up - 0.5) * 2\n",
        "    multiplier = base_mult + (0.7 * confidence)\n",
        "\n",
        "    if atr_value is None or np.isnan(atr_value) or atr_value <= 0:\n",
        "        fallback_pct = 0.03\n",
        "        if signal == \"BELI\":\n",
        "            stop = last_close * (1 - fallback_pct)\n",
        "            return stop, fallback_pct * 100, \"Fallback 3% (ATR tidak valid)\"\n",
        "        stop = last_close * (1 + fallback_pct)\n",
        "        return stop, fallback_pct * 100, \"Fallback 3% (ATR tidak valid, skenario short)\"\n",
        "\n",
        "    if signal == \"BELI\":\n",
        "        stop = last_close - (multiplier * atr_value)\n",
        "        stop_pct = ((last_close - stop) / last_close) * 100\n",
        "        return stop, stop_pct, f\"ATR x {multiplier:.2f} di bawah harga masuk\"\n",
        "\n",
        "    stop = last_close + (multiplier * atr_value)\n",
        "    stop_pct = ((stop - last_close) / last_close) * 100\n",
        "    return stop, stop_pct, f\"ATR x {multiplier:.2f} di atas harga referensi\""
      ],
      "metadata": {
        "id": "qIy3oru7HmNM"
      },
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forecast_next_periods(last_close: float, expected_return: float, start_date: pd.Timestamp, periods: int, interval: str) -> pd.DataFrame:\n",
        "    if interval in {\"1h\", \"60m\"}:\n",
        "        future_index = pd.date_range(start=start_date + pd.Timedelta(hours=1), periods=periods, freq=\"h\")\n",
        "        price_col = \"Predicted_Close_1h\"\n",
        "        ret_col = \"Expected_Hourly_Return\"\n",
        "    else:\n",
        "        future_index = pd.bdate_range(start=start_date + pd.Timedelta(days=1), periods=periods)\n",
        "        price_col = \"Predicted_Close_1d\"\n",
        "        ret_col = \"Expected_Daily_Return\"\n",
        "\n",
        "    prices, price = [], float(last_close)\n",
        "    for _ in range(periods):\n",
        "        price = price * (1 + expected_return)\n",
        "        prices.append(price)\n",
        "\n",
        "    return pd.DataFrame({\"Date\": future_index, price_col: prices, ret_col: expected_return})"
      ],
      "metadata": {
        "id": "ijwYG3GEFpQ3"
      },
      "execution_count": 350,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset() -> tuple[pd.DataFrame, str]:\n",
        "    if INTERVAL in {\"1h\", \"60m\", \"30m\", \"15m\", \"5m\", \"1m\"}:\n",
        "        periods_to_try = [INTRADAY_PERIOD] + [p for p in INTRADAY_FALLBACK_PERIODS if p != INTRADAY_PERIOD]\n",
        "        for period in periods_to_try:\n",
        "            raw = download_data(SYMBOL, INTERVAL, START, END, period)\n",
        "            raw = apply_as_of_cutoff(raw, AS_OF_DATE)\n",
        "            if raw.empty:\n",
        "                continue\n",
        "            base = raw[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]].copy()\n",
        "            feat = build_features(base)\n",
        "            if len(feat) >= MIN_ROWS_AFTER_FEATURES:\n",
        "                return feat, period\n",
        "        raise ValueError(\n",
        "            f\"Data intraday terlalu sedikit setelah feature engineering. Coba period lebih besar. Tried={periods_to_try}\"\n",
        "        )\n",
        "\n",
        "    raw = download_data(SYMBOL, INTERVAL, START, END, INTRADAY_PERIOD)\n",
        "    raw = apply_as_of_cutoff(raw, AS_OF_DATE)\n",
        "    base = raw[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]].copy()\n",
        "    feat = build_features(base)\n",
        "    if len(feat) < MIN_ROWS_AFTER_FEATURES:\n",
        "        raise ValueError(f\"Data harian terlalu sedikit setelah feature engineering: {len(feat)} baris\")\n",
        "    return feat, \"start/end\""
      ],
      "metadata": {
        "id": "ryBd0wLdQGIr"
      },
      "execution_count": 351,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    df, data_window_used = prepare_dataset()\n",
        "    train_df, val_df, test_df = split_time_series(df)\n",
        "    feature_cols = [c for c in df.columns if c != \"Target\"]\n",
        "\n",
        "    X_train, y_train = train_df[feature_cols], train_df[\"Target\"].to_numpy()\n",
        "    X_val, y_val = val_df[feature_cols], val_df[\"Target\"].to_numpy()\n",
        "    X_test, y_test = test_df[feature_cols], test_df[\"Target\"].to_numpy()\n",
        "\n",
        "    X_train = replace_inf_with_nan(X_train)\n",
        "    X_val = replace_inf_with_nan(X_val)\n",
        "    X_test = replace_inf_with_nan(X_test)\n",
        "\n",
        "    candidates = get_model_candidates()\n",
        "    evaluations = [evaluate_model(name, model, X_train, y_train, X_val, y_val) for name, model in candidates.items()]\n",
        "    best = max(evaluations, key=lambda x: (x[\"val_bacc\"], np.nan_to_num(x[\"val_auc\"], nan=-1.0)))\n",
        "\n",
        "    best_model = best[\"model\"]\n",
        "    best_threshold = best[\"threshold\"]\n",
        "\n",
        "    probs_up = np.nan_to_num(best_model.predict_proba(X_test)[:, 1], nan=0.5, posinf=1.0, neginf=0.0)\n",
        "    probs_down = 1 - probs_up\n",
        "    preds = (probs_up >= best_threshold).astype(int)\n",
        "\n",
        "    print(f\"Mode interval: {INTERVAL}\")\n",
        "    print(f\"Data window used: {data_window_used}\")\n",
        "    print(f\"As-of cutoff: {AS_OF_DATE if AS_OF_DATE else 'latest available'}\")\n",
        "    print(\"Model candidates (validation):\")\n",
        "    for ev in evaluations:\n",
        "        auc_text = \"nan\" if np.isnan(ev[\"val_auc\"]) else f\"{ev['val_auc']:.4f}\"\n",
        "        print(\n",
        "            f\"- {ev['name']}: AUC={auc_text}, \"\n",
        "            f\"BalancedAcc={ev['val_bacc']:.4f}, Acc={ev['val_acc']:.4f}, Threshold={ev['threshold']:.2f}\"\n",
        "        )\n",
        "\n",
        "    print(f\"\\nModel terpilih: {best['name']}\")\n",
        "    print(f\"Best threshold (validation): {best_threshold:.2f}\")\n",
        "    print(f\"Test accuracy: {accuracy_score(y_test, preds):.4f}\")\n",
        "    print(f\"Test balanced accuracy: {balanced_accuracy_score(y_test, preds):.4f}\")\n",
        "    print(f\"Test ROC-AUC: {safe_auc(y_test, probs_up):.4f}\" if len(np.unique(y_test)) > 1 else \"Test ROC-AUC: nan\")\n",
        "    print(confusion_matrix(y_test, preds))\n",
        "    print(classification_report(y_test, preds, digits=4, zero_division=0))\n",
        "\n",
        "    result = pd.DataFrame(\n",
        "        {\n",
        "            \"Date\": test_df.index,\n",
        "            \"Close\": test_df[\"Close\"].to_numpy().reshape(-1),\n",
        "            \"Prob_Naik\": probs_up,\n",
        "            \"Prob_Turun\": probs_down,\n",
        "            \"Aktual\": np.where(y_test == 1, \"NAIK\", \"TURUN\"),\n",
        "        }\n",
        "    )\n",
        "    result[\"Signal\"] = result[\"Prob_Naik\"].apply(lambda p: decide_signal(float(p), best_threshold))\n",
        "\n",
        "    print(\"\\nContoh output (10 baris terakhir):\")\n",
        "    print(result.tail(10).to_string(index=False))\n",
        "\n",
        "    latest_row = replace_inf_with_nan(df[feature_cols].tail(1))\n",
        "    prob_up_now = float(np.nan_to_num(best_model.predict_proba(latest_row)[:, 1], nan=0.5, posinf=1.0, neginf=0.0)[0])\n",
        "    prob_down_now = 1 - prob_up_now\n",
        "    signal_now = decide_signal(prob_up_now, best_threshold)\n",
        "    atr_now = float(df[\"ATR\"].iloc[-1]) if \"ATR\" in df.columns else np.nan\n",
        "    stoploss_price, stoploss_pct, stoploss_note = suggest_stoploss(\n",
        "        signal=signal_now,\n",
        "        last_close=float(df[\"Close\"].iloc[-1]),\n",
        "        atr_value=atr_now,\n",
        "        prob_up=prob_up_now,\n",
        "    )\n",
        "\n",
        "    print(\"\\nSignal saat ini:\")\n",
        "    print(f\"Timestamp terakhir   : {df.index[-1]}\")\n",
        "    print(f\"Prob_Naik saat ini   : {prob_up_now:.4f}\")\n",
        "    print(f\"Prob_Turun saat ini  : {prob_down_now:.4f}\")\n",
        "    print(f\"Signal saat ini      : {signal_now}\")\n",
        "    if stoploss_price is not None:\n",
        "        print(f\"Stop-loss saran      : {stoploss_price:.2f} ({stoploss_pct:.2f}%)\")\n",
        "    print(f\"Catatan stop-loss    : {stoploss_note}\")\n",
        "\n",
        "    expected_ret = estimate_expected_return(prob_up_now, train_df[\"Return\"])\n",
        "\n",
        "    if INTERVAL in {\"1h\", \"60m\"}:\n",
        "        forecast = forecast_next_periods(\n",
        "            last_close=float(df[\"Close\"].iloc[-1]),\n",
        "            expected_return=expected_ret,\n",
        "            start_date=df.index[-1],\n",
        "            periods=24,\n",
        "            interval=INTERVAL,\n",
        "        )\n",
        "        print(\"\\nPrediksi harga 24 jam ke depan (hourly):\")\n",
        "        print(forecast.to_string(index=False))\n",
        "    else:\n",
        "        forecast = forecast_next_periods(\n",
        "            last_close=float(df[\"Close\"].iloc[-1]),\n",
        "            expected_return=expected_ret,\n",
        "            start_date=df.index[-1],\n",
        "            periods=5,\n",
        "            interval=INTERVAL,\n",
        "        )\n",
        "        print(\"\\nPrediksi harga 1 minggu ke depan (5 hari bursa):\")\n",
        "        print(forecast.to_string(index=False))"
      ],
      "metadata": {
        "id": "VmoTqF0aMU_R"
      },
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRo_zVMVFvCC",
        "outputId": "1b7c87c3-c584-4274-f9a6-b273312fbae8"
      },
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mode interval: 1h\n",
            "Data window used: 30d\n",
            "As-of cutoff: latest available\n",
            "Model candidates (validation):\n",
            "- HistGradientBoosting: AUC=0.7917, BalancedAcc=0.7500, Acc=0.6250, Threshold=0.58\n",
            "- RandomForest: AUC=0.6250, BalancedAcc=0.7500, Acc=0.6250, Threshold=0.57\n",
            "- LogisticRegression: AUC=0.5833, BalancedAcc=0.7083, Acc=0.8125, Threshold=0.59\n",
            "\n",
            "Model terpilih: HistGradientBoosting\n",
            "Best threshold (validation): 0.58\n",
            "Test accuracy: 0.5294\n",
            "Test balanced accuracy: 0.5143\n",
            "Test ROC-AUC: 0.4429\n",
            "[[6 4]\n",
            " [4 3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6000    0.6000    0.6000        10\n",
            "           1     0.4286    0.4286    0.4286         7\n",
            "\n",
            "    accuracy                         0.5294        17\n",
            "   macro avg     0.5143    0.5143    0.5143        17\n",
            "weighted avg     0.5294    0.5294    0.5294        17\n",
            "\n",
            "\n",
            "Contoh output (10 baris terakhir):\n",
            "                     Date  Close  Prob_Naik  Prob_Turun Aktual Signal\n",
            "2026-02-24 02:00:00+00:00  286.0   0.493188    0.506812   NAIK   JUAL\n",
            "2026-02-24 04:00:00+00:00  286.0   0.566303    0.433697   NAIK  TAHAN\n",
            "2026-02-24 06:00:00+00:00  288.0   0.390722    0.609278  TURUN   JUAL\n",
            "2026-02-24 07:00:00+00:00  276.0   0.375116    0.624884  TURUN   JUAL\n",
            "2026-02-24 09:00:00+00:00  274.0   0.503695    0.496305  TURUN  TAHAN\n",
            "2026-02-25 03:00:00+00:00  268.0   0.598158    0.401842   NAIK  TAHAN\n",
            "2026-02-25 04:00:00+00:00  270.0   0.694836    0.305164   NAIK   BELI\n",
            "2026-02-25 07:00:00+00:00  268.0   0.649347    0.350653   NAIK   BELI\n",
            "2026-02-25 08:00:00+00:00  272.0   0.719763    0.280237  TURUN   BELI\n",
            "2026-02-25 09:00:00+00:00  270.0   0.887370    0.112630  TURUN   BELI\n",
            "\n",
            "Signal saat ini:\n",
            "Timestamp terakhir   : 2026-02-25 09:00:00+00:00\n",
            "Prob_Naik saat ini   : 0.8874\n",
            "Prob_Turun saat ini  : 0.1126\n",
            "Signal saat ini      : BELI\n",
            "Stop-loss saran      : 257.05 (4.79%)\n",
            "Catatan stop-loss    : ATR x 2.04 di bawah harga masuk\n",
            "\n",
            "Prediksi harga 24 jam ke depan (hourly):\n",
            "                     Date  Predicted_Close_1h  Expected_Hourly_Return\n",
            "2026-02-25 10:00:00+00:00          275.571338                0.020635\n",
            "2026-02-25 11:00:00+00:00          281.257639                0.020635\n",
            "2026-02-25 12:00:00+00:00          287.061274                0.020635\n",
            "2026-02-25 13:00:00+00:00          292.984664                0.020635\n",
            "2026-02-25 14:00:00+00:00          299.030282                0.020635\n",
            "2026-02-25 15:00:00+00:00          305.200648                0.020635\n",
            "2026-02-25 16:00:00+00:00          311.498337                0.020635\n",
            "2026-02-25 17:00:00+00:00          317.925976                0.020635\n",
            "2026-02-25 18:00:00+00:00          324.486247                0.020635\n",
            "2026-02-25 19:00:00+00:00          331.181887                0.020635\n",
            "2026-02-25 20:00:00+00:00          338.015688                0.020635\n",
            "2026-02-25 21:00:00+00:00          344.990502                0.020635\n",
            "2026-02-25 22:00:00+00:00          352.109238                0.020635\n",
            "2026-02-25 23:00:00+00:00          359.374866                0.020635\n",
            "2026-02-26 00:00:00+00:00          366.790418                0.020635\n",
            "2026-02-26 01:00:00+00:00          374.358986                0.020635\n",
            "2026-02-26 02:00:00+00:00          382.083729                0.020635\n",
            "2026-02-26 03:00:00+00:00          389.967869                0.020635\n",
            "2026-02-26 04:00:00+00:00          398.014694                0.020635\n",
            "2026-02-26 05:00:00+00:00          406.227563                0.020635\n",
            "2026-02-26 06:00:00+00:00          414.609900                0.020635\n",
            "2026-02-26 07:00:00+00:00          423.165204                0.020635\n",
            "2026-02-26 08:00:00+00:00          431.897043                0.020635\n",
            "2026-02-26 09:00:00+00:00          440.809060                0.020635\n"
          ]
        }
      ]
    }
  ]
}